{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4448c781",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.007581,
     "end_time": "2025-08-11T04:45:59.597130",
     "exception": false,
     "start_time": "2025-08-11T04:45:59.589549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "159eb6a6",
   "metadata": {
    "papermill": {
     "duration": 0.006219,
     "end_time": "2025-08-11T04:45:59.609969",
     "exception": false,
     "start_time": "2025-08-11T04:45:59.603750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# What is One-Hot Encoding?\n",
    "\n",
    "It represents each word with a vector of all 0s, except a single 1 at the index of that word in the vocabulary.\n",
    "\n",
    "\n",
    "vocab = [\"cat\", \"dog\", \"fish\"]\n",
    "\n",
    "**One-hot encoded vectors:**\n",
    "\n",
    "\"cat\"  ‚Üí [1, 0, 0]  \n",
    "\"dog\"  ‚Üí [0, 1, 0]  \n",
    "\"fish\" ‚Üí [0, 0, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b31574",
   "metadata": {
    "papermill": {
     "duration": 0.006702,
     "end_time": "2025-08-11T04:45:59.622902",
     "exception": false,
     "start_time": "2025-08-11T04:45:59.616200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚ùå Major Cons of One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d2d2f",
   "metadata": {
    "papermill": {
     "duration": 0.006392,
     "end_time": "2025-08-11T04:45:59.635618",
     "exception": false,
     "start_time": "2025-08-11T04:45:59.629226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**1Ô∏è‚É£ Sparsity (Wasted Space & Memory)**\n",
    "\n",
    "If you have a large vocabulary, the vector becomes huge and mostly filled with zeros ‚Äî which wastes space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "310c7e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T04:45:59.649790Z",
     "iopub.status.busy": "2025-08-11T04:45:59.649124Z",
     "iopub.status.idle": "2025-08-11T04:45:59.657952Z",
     "shell.execute_reply": "2025-08-11T04:45:59.657294Z"
    },
    "papermill": {
     "duration": 0.017133,
     "end_time": "2025-08-11T04:45:59.658980",
     "exception": false,
     "start_time": "2025-08-11T04:45:59.641847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector size: 10000\n",
      "Non-zero entries: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# A large vocab (e.g., 10,000 words)\n",
    "vocab_size = 10000\n",
    "word_index = 4321  # Random word index\n",
    "\n",
    "# One-hot encoding that word\n",
    "vector = np.zeros(vocab_size)\n",
    "vector[word_index] = 1\n",
    "\n",
    "print(f\"Vector size: {len(vector)}\")\n",
    "print(f\"Non-zero entries: {np.count_nonzero(vector)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df216ce",
   "metadata": {
    "papermill": {
     "duration": 0.006348,
     "end_time": "2025-08-11T04:45:59.671752",
     "exception": false,
     "start_time": "2025-08-11T04:45:59.665404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**2Ô∏è‚É£ No Semantic Meaning or Similarity**\n",
    "\n",
    "Words like \"king\" and \"queen\", or \"run\" and \"jog\", are treated as completely unrelated ‚Äî no similarity is captured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc0505da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T04:45:59.685173Z",
     "iopub.status.busy": "2025-08-11T04:45:59.684950Z",
     "iopub.status.idle": "2025-08-11T04:46:00.804635Z",
     "shell.execute_reply": "2025-08-11T04:46:00.803770Z"
    },
    "papermill": {
     "duration": 1.127843,
     "end_time": "2025-08-11T04:46:00.805970",
     "exception": false,
     "start_time": "2025-08-11T04:45:59.678127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king vs queen: 0.0\n",
      "run vs bottle: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# One-hot vectors\n",
    "king = np.array([[1, 0, 0, 0]])\n",
    "queen = np.array([[0, 1, 0, 0]])\n",
    "run = np.array([[0, 0, 1, 0]])\n",
    "bottle = np.array([[0, 0, 0, 1]])\n",
    "\n",
    "# Cosine similarity between \"king\" and \"queen\"\n",
    "print(\"king vs queen:\", cosine_similarity(king, queen)[0][0])\n",
    "print(\"run vs bottle:\", cosine_similarity(run, bottle)[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b832290",
   "metadata": {
    "papermill": {
     "duration": 0.006428,
     "end_time": "2025-08-11T04:46:00.820054",
     "exception": false,
     "start_time": "2025-08-11T04:46:00.813626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "295602e7",
   "metadata": {
    "papermill": {
     "duration": 0.006809,
     "end_time": "2025-08-11T04:46:00.833355",
     "exception": false,
     "start_time": "2025-08-11T04:46:00.826546",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**3Ô∏è‚É£ No Context / Word Order Information**\n",
    "\n",
    "One-hot encoding can‚Äôt tell if the word is the subject or object, or what other words are nearby.\n",
    "\n",
    "Sentence 1: \"Dog bites man\"\n",
    "Sentence 2: \"Man bites dog\"\n",
    "\n",
    "Same words ‚Üí same one-hot vectors ‚Äî even though meanings are opposite.\n",
    "\n",
    "No way to tell who did what to whom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf0973",
   "metadata": {
    "papermill": {
     "duration": 0.00607,
     "end_time": "2025-08-11T04:46:00.845847",
     "exception": false,
     "start_time": "2025-08-11T04:46:00.839777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6fe054e",
   "metadata": {
    "papermill": {
     "duration": 0.0061,
     "end_time": "2025-08-11T04:46:00.858213",
     "exception": false,
     "start_time": "2025-08-11T04:46:00.852113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**4Ô∏è‚É£ Out-of-Vocabulary (OOV) Problem**\n",
    "\n",
    " Problem:\n",
    "If a new word is seen during testing that wasn't in training vocab, we can‚Äôt encode it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70c68f33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T04:46:00.872260Z",
     "iopub.status.busy": "2025-08-11T04:46:00.871911Z",
     "iopub.status.idle": "2025-08-11T04:46:00.876913Z",
     "shell.execute_reply": "2025-08-11T04:46:00.876215Z"
    },
    "papermill": {
     "duration": 0.013594,
     "end_time": "2025-08-11T04:46:00.877992",
     "exception": false,
     "start_time": "2025-08-11T04:46:00.864398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'lion' not in vocabulary!\n"
     ]
    }
   ],
   "source": [
    "vocab = {\"cat\": 0, \"dog\": 1, \"fish\": 2}\n",
    "test_word = \"lion\"\n",
    "\n",
    "\n",
    "if test_word in vocab:\n",
    "    vec = np.zeros(len(vocab))\n",
    "    vec[vocab[test_word]] = 1\n",
    "else:\n",
    "    print(f\"'{test_word}' not in vocabulary!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c173dce6",
   "metadata": {
    "papermill": {
     "duration": 0.006258,
     "end_time": "2025-08-11T04:46:00.890547",
     "exception": false,
     "start_time": "2025-08-11T04:46:00.884289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9d42ff",
   "metadata": {
    "papermill": {
     "duration": 0.006066,
     "end_time": "2025-08-11T04:46:00.902781",
     "exception": false,
     "start_time": "2025-08-11T04:46:00.896715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a92503f",
   "metadata": {
    "papermill": {
     "duration": 0.00605,
     "end_time": "2025-08-11T04:46:00.915159",
     "exception": false,
     "start_time": "2025-08-11T04:46:00.909109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "üß∫ What is Bag of Words (BoW)?\n",
    "\n",
    "BoW is a text representation technique where we represent a document as a vector of word counts.\n",
    "\n",
    "It counts the occurrence of each word in a document.\n",
    "\n",
    "It ignores grammar, order, and meaning ‚Äî just focuses on word frequency.\n",
    "\n",
    "It's used for text classification, sentiment analysis, and many traditional NLP tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6e36bf",
   "metadata": {
    "papermill": {
     "duration": 0.006383,
     "end_time": "2025-08-11T04:46:00.975942",
     "exception": false,
     "start_time": "2025-08-11T04:46:00.969559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üß∫ What is BoW?\n",
    "\n",
    "BoW represents each document as a vector of word frequencies from a fixed vocabulary.\n",
    "\n",
    "It ignores order, grammar, and context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875d5326",
   "metadata": {
    "papermill": {
     "duration": 0.006218,
     "end_time": "2025-08-11T04:46:00.988459",
     "exception": false,
     "start_time": "2025-08-11T04:46:00.982241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "üìò Example:\n",
    "\n",
    "Corpus:\n",
    "\n",
    "\n",
    "Doc1: \"I love NLP\",\n",
    "Doc2: \"NLP is fun\"\n",
    "\n",
    "\n",
    "Vocabulary:\n",
    "\n",
    "\n",
    "[\"I\", \"love\", \"NLP\", \"is\", \"fun\"]\n",
    "\n",
    "Vector for:\n",
    "\n",
    "Doc1 ‚Üí [1, 1, 1, 0, 0]\n",
    "\n",
    "Doc2 ‚Üí [0, 0, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4112d9d",
   "metadata": {
    "papermill": {
     "duration": 0.006287,
     "end_time": "2025-08-11T04:46:01.001128",
     "exception": false,
     "start_time": "2025-08-11T04:46:00.994841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b96b18c0",
   "metadata": {
    "papermill": {
     "duration": 0.006288,
     "end_time": "2025-08-11T04:46:01.013820",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.007532",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "‚ùå Main Disadvantages of BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81af977",
   "metadata": {
    "papermill": {
     "duration": 0.006286,
     "end_time": "2025-08-11T04:46:01.026708",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.020422",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1Ô∏è‚É£ No Understanding of Word Meaning (No Semantics)\n",
    "\n",
    "Problem:\n",
    "Words like \"good\" and \"great\" are treated as completely unrelated ‚Äî even though they mean similar things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb6fb490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T04:46:01.040997Z",
     "iopub.status.busy": "2025-08-11T04:46:01.040269Z",
     "iopub.status.idle": "2025-08-11T04:46:01.060905Z",
     "shell.execute_reply": "2025-08-11T04:46:01.060077Z"
    },
    "papermill": {
     "duration": 0.028954,
     "end_time": "2025-08-11T04:46:01.062005",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.033051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good' 'great' 'is' 'phone' 'this']\n",
      "[[1 0 1 1 1]\n",
      " [0 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "docs = [\"This phone is good\", \"This phone is great\"]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(docs)\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab6f192",
   "metadata": {
    "papermill": {
     "duration": 0.006652,
     "end_time": "2025-08-11T04:46:01.075806",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.069154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " **Even though \"good\" and \"great\" are synonyms, the vectors are totally different.**\n",
    "\n",
    "**BoW doesn‚Äôt understand meaning or similarity.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b52f20",
   "metadata": {
    "papermill": {
     "duration": 0.006714,
     "end_time": "2025-08-11T04:46:01.089516",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.082802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da67e62f",
   "metadata": {
    "papermill": {
     "duration": 0.006327,
     "end_time": "2025-08-11T04:46:01.102156",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.095829",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2Ô∏è‚É£ No Word Order or Grammar\n",
    "\n",
    "Problem:\n",
    "BoW doesn't know who is doing what to whom ‚Äî so two opposite sentences can have the same vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffd22790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T04:46:01.117758Z",
     "iopub.status.busy": "2025-08-11T04:46:01.117486Z",
     "iopub.status.idle": "2025-08-11T04:46:01.124592Z",
     "shell.execute_reply": "2025-08-11T04:46:01.123710Z"
    },
    "papermill": {
     "duration": 0.016517,
     "end_time": "2025-08-11T04:46:01.125798",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.109281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bites' 'dog' 'man']\n",
      "[[1 1 1]\n",
      " [1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "docs = [\"dog bites man\", \"man bites dog\"]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(docs)\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3a8665",
   "metadata": {
    "papermill": {
     "duration": 0.006725,
     "end_time": "2025-08-11T04:46:01.139382",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.132657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "**Both vectors are identical even though:\"dog bites man\" ‚úÖ\"man bites dog\" (different meaning!)**\n",
    "\n",
    "**Word position and sentence structure is completely lost.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2f48e",
   "metadata": {
    "papermill": {
     "duration": 0.006695,
     "end_time": "2025-08-11T04:46:01.152689",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.145994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c019aad4",
   "metadata": {
    "papermill": {
     "duration": 0.00645,
     "end_time": "2025-08-11T04:46:01.166073",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.159623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "3Ô∏è‚É£ High Dimensionality (Sparsity)\n",
    "\n",
    "Problem:\n",
    "If your vocabulary is large (e.g. 50,000+ words), each document becomes a huge sparse vector ‚Äî full of zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03bd4927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T04:46:01.180917Z",
     "iopub.status.busy": "2025-08-11T04:46:01.180644Z",
     "iopub.status.idle": "2025-08-11T04:46:01.185745Z",
     "shell.execute_reply": "2025-08-11T04:46:01.185115Z"
    },
    "papermill": {
     "duration": 0.013919,
     "end_time": "2025-08-11T04:46:01.186889",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.172970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector length: 10000\n",
      "Non-zero entries: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vocab_size = 10000\n",
    "vector = np.zeros(vocab_size)\n",
    "vector[100] = 1  # Only one word used in the doc\n",
    "\n",
    "print(f\"Vector length: {len(vector)}\")\n",
    "print(f\"Non-zero entries: {np.count_nonzero(vector)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e573e5",
   "metadata": {
    "papermill": {
     "duration": 0.006384,
     "end_time": "2025-08-11T04:46:01.200173",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.193789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06abab6f",
   "metadata": {
    "papermill": {
     "duration": 0.006349,
     "end_time": "2025-08-11T04:46:01.212948",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.206599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**4Ô∏è‚É£ Out-of-Vocabulary (OOV) Problem**\n",
    "\n",
    "\n",
    "üîç Problem:\n",
    "BoW model can't handle new words not seen during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7ec5244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T04:46:01.226899Z",
     "iopub.status.busy": "2025-08-11T04:46:01.226704Z",
     "iopub.status.idle": "2025-08-11T04:46:01.232192Z",
     "shell.execute_reply": "2025-08-11T04:46:01.231554Z"
    },
    "papermill": {
     "duration": 0.013756,
     "end_time": "2025-08-11T04:46:01.233265",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.219509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fun' 'is' 'nlp']\n",
      "[[1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "train_docs = [\"NLP is fun\"]\n",
    "test_docs = [\"AI is fun\"]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_docs)\n",
    "\n",
    "# Now transform test data\n",
    "X_test = vectorizer.transform(test_docs)\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X_test.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79f6212",
   "metadata": {
    "papermill": {
     "duration": 0.006486,
     "end_time": "2025-08-11T04:46:01.246297",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.239811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**New word \"AI\" is ignored, model may misbehave.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941b5627",
   "metadata": {
    "papermill": {
     "duration": 0.006398,
     "end_time": "2025-08-11T04:46:01.259256",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.252858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98f86a7c",
   "metadata": {
    "papermill": {
     "duration": 0.006388,
     "end_time": "2025-08-11T04:46:01.272198",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.265810",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚úÖ Advantages of Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5b409e",
   "metadata": {
    "papermill": {
     "duration": 0.009814,
     "end_time": "2025-08-11T04:46:01.288570",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.278756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1Ô∏è‚É£ Simple and Easy to Implement\n",
    "\n",
    "Very intuitive: just count how many times each word appears.\n",
    "\n",
    "Easy to implement using tools like CountVectorizer in scikit-learn.\n",
    "\n",
    "üîß Good for beginners and quick prototypes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c55d6",
   "metadata": {
    "papermill": {
     "duration": 0.010999,
     "end_time": "2025-08-11T04:46:01.309108",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.298109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2Ô∏è‚É£ Fast to Train and Use\n",
    "\n",
    "Since it doesn‚Äôt require training like Word2Vec or BERT, it‚Äôs fast and lightweight.\n",
    "\n",
    "Works well with classical ML models like:\n",
    "\n",
    "Naive Bayes\n",
    "\n",
    "Logistic Regression\n",
    "\n",
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "704d295f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T04:46:01.327253Z",
     "iopub.status.busy": "2025-08-11T04:46:01.326985Z",
     "iopub.status.idle": "2025-08-11T04:46:01.353765Z",
     "shell.execute_reply": "2025-08-11T04:46:01.353114Z"
    },
    "papermill": {
     "duration": 0.035399,
     "end_time": "2025-08-11T04:46:01.354846",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.319447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "docs = [\"I love this phone\", \"This phone is terrible\"]\n",
    "labels = [1, 0]  # 1 = Positive, 0 = Negative\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(docs)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985f792c",
   "metadata": {
    "papermill": {
     "duration": 0.006669,
     "end_time": "2025-08-11T04:46:01.368682",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.362013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**3Ô∏è‚É£ Good Performance on Small or Clean Datasets**\n",
    "\n",
    "If the text is short and vocabulary is limited (e.g., SMS spam detection, news headlines), BoW can give surprisingly good results.\n",
    "\n",
    "‚úîÔ∏è Works best when:\n",
    "\n",
    "Grammar doesn‚Äôt matter much.\n",
    "\n",
    "Word presence matters more than order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39437c4",
   "metadata": {
    "papermill": {
     "duration": 0.006552,
     "end_time": "2025-08-11T04:46:01.381923",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.375371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eb79e0",
   "metadata": {
    "papermill": {
     "duration": 0.006594,
     "end_time": "2025-08-11T04:46:01.395226",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.388632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e856dd00",
   "metadata": {
    "papermill": {
     "duration": 0.0066,
     "end_time": "2025-08-11T04:46:01.408534",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.401934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bac0eb2",
   "metadata": {
    "papermill": {
     "duration": 0.006464,
     "end_time": "2025-08-11T04:46:01.421607",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.415143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# N-grams (Uni-grams, Bi-grams, Tri-grams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddd1a79",
   "metadata": {
    "papermill": {
     "duration": 0.008782,
     "end_time": "2025-08-11T04:46:01.437538",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.428756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Concept\n",
    "\n",
    "N-grams are continuous sequences of N words from a sentence.\n",
    "This helps preserve word order and context compared to plain BoW."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7291560",
   "metadata": {
    "papermill": {
     "duration": 0.011274,
     "end_time": "2025-08-11T04:46:01.459496",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.448222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "| N-gram Type | Example for sentence: `\"People watch movies\"` |\n",
    "| ----------- | --------------------------------------------- |\n",
    "| Uni-grams   | \\[\"People\", \"watch\", \"movies\"]                |\n",
    "| Bi-grams    | \\[\"People watch\", \"watch movies\"]             |\n",
    "| Tri-grams   | \\[\"People watch movies\"]                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a506a570",
   "metadata": {
    "papermill": {
     "duration": 0.011036,
     "end_time": "2025-08-11T04:46:01.483766",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.472730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So, instead of just individual words, we also consider word pairs, triplets, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5308909",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T04:46:01.507262Z",
     "iopub.status.busy": "2025-08-11T04:46:01.506546Z",
     "iopub.status.idle": "2025-08-11T04:46:01.515317Z",
     "shell.execute_reply": "2025-08-11T04:46:01.514395Z"
    },
    "papermill": {
     "duration": 0.01932,
     "end_time": "2025-08-11T04:46:01.516833",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.497513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi-gram Vocabulary:\n",
      "['do not' 'is not' 'like spam' 'love nlp' 'nlp is' 'not boring' 'not like']\n",
      "\n",
      "Bi-gram Vectors:\n",
      "[[0 0 0 1 0 0 0]\n",
      " [0 1 0 0 1 1 0]\n",
      " [1 0 1 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sentences = [\n",
    "    \"I love NLP\",\n",
    "    \"NLP is not boring\",\n",
    "    \"I do not like spam\"\n",
    "]\n",
    "\n",
    "# Bi-grams only (n=2)\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "X = vectorizer.fit_transform(sentences)\n",
    "\n",
    "print(\"Bi-gram Vocabulary:\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"\\nBi-gram Vectors:\")\n",
    "print(X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5196fb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T04:46:01.539429Z",
     "iopub.status.busy": "2025-08-11T04:46:01.538820Z",
     "iopub.status.idle": "2025-08-11T04:46:01.544463Z",
     "shell.execute_reply": "2025-08-11T04:46:01.543652Z"
    },
    "papermill": {
     "duration": 0.019714,
     "end_time": "2025-08-11T04:46:01.545514",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.525800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tri-gram Vocabulary:\n",
      "['language processing is' 'love natural language'\n",
      " 'natural language processing' 'processing is fun']\n",
      "\n",
      "Tri-gram Vectors:\n",
      "[[0 1 1 0]\n",
      " [1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sentences = [\n",
    "    \"I love natural language processing\",\n",
    "    \"Natural language processing is fun\"\n",
    "]\n",
    "\n",
    "# Tri-gram representation\n",
    "vectorizer = CountVectorizer(ngram_range=(3, 3))\n",
    "X = vectorizer.fit_transform(sentences)\n",
    "\n",
    "# Output\n",
    "print(\"Tri-gram Vocabulary:\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"\\nTri-gram Vectors:\")\n",
    "print(X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105b482",
   "metadata": {
    "papermill": {
     "duration": 0.008907,
     "end_time": "2025-08-11T04:46:01.561535",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.552628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b68c1a8",
   "metadata": {
    "papermill": {
     "duration": 0.007203,
     "end_time": "2025-08-11T04:46:01.577490",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.570287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# advantage of N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59d01cc",
   "metadata": {
    "papermill": {
     "duration": 0.008833,
     "end_time": "2025-08-11T04:46:01.593474",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.584641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**1. Captures context**\n",
    "   \n",
    "Explanation:\n",
    "Unlike Bag-of-Words (which treats \"New York\" and \"York New\" the same because it ignores order), N-grams preserve word order, so the position of words affects the token representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9ea7db1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T04:46:01.608666Z",
     "iopub.status.busy": "2025-08-11T04:46:01.608033Z",
     "iopub.status.idle": "2025-08-11T04:46:01.614813Z",
     "shell.execute_reply": "2025-08-11T04:46:01.614104Z"
    },
    "papermill": {
     "duration": 0.015503,
     "end_time": "2025-08-11T04:46:01.615931",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.600428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigrams vocabulary: {'live': 1, 'in': 0, 'new': 2, 'york': 3}\n",
      "[[1 1 1 1]\n",
      " [1 1 1 1]]\n",
      "\n",
      "Bigrams vocabulary: {'live in': 2, 'in new': 0, 'new york': 3, 'in york': 1, 'york new': 4}\n",
      "[[1 0 1 1 0]\n",
      " [0 1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts = [\"I live in New York\", \"I live in York New\"]\n",
    "\n",
    "# Using unigrams (BoW)\n",
    "vectorizer_uni = CountVectorizer(ngram_range=(1,1))\n",
    "unigrams = vectorizer_uni.fit_transform(texts)\n",
    "print(\"Unigrams vocabulary:\", vectorizer_uni.vocabulary_)\n",
    "print(unigrams.toarray())\n",
    "\n",
    "# Using bigrams\n",
    "vectorizer_bi = CountVectorizer(ngram_range=(2,2))\n",
    "bigrams = vectorizer_bi.fit_transform(texts)\n",
    "print(\"\\nBigrams vocabulary:\", vectorizer_bi.vocabulary_)\n",
    "print(bigrams.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ba99b",
   "metadata": {
    "papermill": {
     "duration": 0.007076,
     "end_time": "2025-08-11T04:46:01.630201",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.623125",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Math Insight: In unigram BoW, the vector is\n",
    "\n",
    "[count(live), count(in), count(new), count(york)]\n",
    "Both sentences ‚Üí [1, 1, 1, 1] (identical).\n",
    "\n",
    "In bigram, the position changes token identity: \"new york\" ‚â† \"york new\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4e5e99",
   "metadata": {
    "papermill": {
     "duration": 0.006779,
     "end_time": "2025-08-11T04:46:01.644216",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.637437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faaaf447",
   "metadata": {
    "papermill": {
     "duration": 0.007099,
     "end_time": "2025-08-11T04:46:01.658239",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.651140",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Detects phrases**\n",
    "\n",
    "Explanation:\n",
    "Some phrases have meaning that cannot be inferred from individual words (\"machine learning\" ‚â† \"machine\" + \"learning\" separately)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25da123b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T04:46:01.673926Z",
     "iopub.status.busy": "2025-08-11T04:46:01.673204Z",
     "iopub.status.idle": "2025-08-11T04:46:01.679129Z",
     "shell.execute_reply": "2025-08-11T04:46:01.678440Z"
    },
    "papermill": {
     "duration": 0.014915,
     "end_time": "2025-08-11T04:46:01.680367",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.665452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams vocabulary: {'love machine': 3, 'machine learning': 4, 'love learning': 2, 'learning about': 1, 'about machines': 0}\n",
      "[[0 0 0 1 1]\n",
      " [1 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "texts = [\"I love machine learning\", \"I love learning about machines\"]\n",
    "\n",
    "vectorizer_bi = CountVectorizer(ngram_range=(2,2))\n",
    "bigrams = vectorizer_bi.fit_transform(texts)\n",
    "print(\"Bigrams vocabulary:\", vectorizer_bi.vocabulary_)\n",
    "print(bigrams.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf85488e",
   "metadata": {
    "papermill": {
     "duration": 0.010233,
     "end_time": "2025-08-11T04:46:01.698026",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.687793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Meaning: \"machine learning\" is treated as one feature instead of two separate unigrams, which preserves semantic meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f035c97",
   "metadata": {
    "papermill": {
     "duration": 0.007461,
     "end_time": "2025-08-11T04:46:01.714180",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.706719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6b3ffce",
   "metadata": {
    "papermill": {
     "duration": 0.013846,
     "end_time": "2025-08-11T04:46:01.738456",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.724610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**3. Improves prediction**\n",
    "\n",
    "Explanation:\n",
    "In next-word prediction tasks, knowing the previous two or more words (bigram/trigram) gives better accuracy than knowing just one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ea2f00a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T04:46:01.754674Z",
     "iopub.status.busy": "2025-08-11T04:46:01.754396Z",
     "iopub.status.idle": "2025-08-11T04:46:01.759751Z",
     "shell.execute_reply": "2025-08-11T04:46:01.759048Z"
    },
    "papermill": {
     "duration": 0.01496,
     "end_time": "2025-08-11T04:46:01.760815",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.745855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram counts: {('i', 'am'): 3, ('am', 'hungry.'): 1, ('hungry.', 'i'): 1, ('am', 'sleepy.'): 1, ('sleepy.', 'i'): 1, ('am', 'happy.'): 1}\n",
      "Likely next words after 'I am': {'hungry.': 1, 'sleepy.': 1, 'happy.': 1}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "corpus = \"I am hungry. I am sleepy. I am happy.\".lower().split()\n",
    "\n",
    "# Build bigram counts\n",
    "bigrams = defaultdict(int)\n",
    "for i in range(len(corpus)-1):\n",
    "    pair = (corpus[i], corpus[i+1])\n",
    "    bigrams[pair] += 1\n",
    "\n",
    "print(\"Bigram counts:\", dict(bigrams))\n",
    "\n",
    "# Predict next word after \"I am\"\n",
    "prefix = (\"i\", \"am\")\n",
    "predictions = {k[1]: v for k, v in bigrams.items() if k[0] == prefix[1]}\n",
    "print(\"Likely next words after 'I am':\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f541745e",
   "metadata": {
    "papermill": {
     "duration": 0.006924,
     "end_time": "2025-08-11T04:46:01.774764",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.767840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Math Insight:\n",
    "In probability terms:\n",
    "\n",
    "ùëÉ\n",
    "(\n",
    "word\n",
    "ùë°\n",
    "‚à£\n",
    "word\n",
    "ùë°\n",
    "‚àí\n",
    "1\n",
    ",\n",
    "word\n",
    "ùë°\n",
    "‚àí\n",
    "2\n",
    ")\n",
    "P(word \n",
    "t\n",
    "‚Äã\n",
    " ‚à£word \n",
    "t‚àí1\n",
    "‚Äã\n",
    " ,word \n",
    "t‚àí2\n",
    "‚Äã\n",
    " )\n",
    "is higher for correct context than\n",
    "\n",
    "ùëÉ\n",
    "(\n",
    "word\n",
    "ùë°\n",
    "‚à£\n",
    "word\n",
    "ùë°\n",
    "‚àí\n",
    "1\n",
    ")\n",
    "P(word \n",
    "t\n",
    "‚Äã\n",
    " ‚à£word \n",
    "t‚àí1\n",
    "‚Äã\n",
    " )\n",
    "because more context narrows the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1312deeb",
   "metadata": {
    "papermill": {
     "duration": 0.00698,
     "end_time": "2025-08-11T04:46:01.788675",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.781695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fddbc0ac",
   "metadata": {
    "papermill": {
     "duration": 0.006859,
     "end_time": "2025-08-11T04:46:01.802488",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.795629",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**4. Negation handling**\n",
    "   \n",
    "Explanation:\n",
    "With unigrams, \"not good\" is treated as \"not\" and \"good\" separately, losing the negation meaning.\n",
    "With bigrams, \"not good\" is a single feature that clearly signals negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12c3fdc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T04:46:01.817820Z",
     "iopub.status.busy": "2025-08-11T04:46:01.817607Z",
     "iopub.status.idle": "2025-08-11T04:46:01.823937Z",
     "shell.execute_reply": "2025-08-11T04:46:01.823064Z"
    },
    "papermill": {
     "duration": 0.015662,
     "end_time": "2025-08-11T04:46:01.825179",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.809517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigrams: [[1 1 0 1]\n",
      " [1 1 1 1]]\n",
      "Bigrams: [[1 0 0 1]\n",
      " [0 1 1 1]]\n",
      "Bigrams vocab: {'this is': 3, 'is good': 0, 'is not': 1, 'not good': 2}\n"
     ]
    }
   ],
   "source": [
    "texts = [\"This is good\", \"This is not good\"]\n",
    "\n",
    "vectorizer_uni = CountVectorizer(ngram_range=(1,1))\n",
    "print(\"Unigrams:\", vectorizer_uni.fit_transform(texts).toarray())\n",
    "\n",
    "vectorizer_bi = CountVectorizer(ngram_range=(2,2))\n",
    "print(\"Bigrams:\", vectorizer_bi.fit_transform(texts).toarray())\n",
    "print(\"Bigrams vocab:\", vectorizer_bi.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2bb43d",
   "metadata": {
    "papermill": {
     "duration": 0.006893,
     "end_time": "2025-08-11T04:46:01.839199",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.832306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b059bdf",
   "metadata": {
    "papermill": {
     "duration": 0.006869,
     "end_time": "2025-08-11T04:46:01.853009",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.846140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b815a0f",
   "metadata": {
    "papermill": {
     "duration": 0.006775,
     "end_time": "2025-08-11T04:46:01.866739",
     "exception": false,
     "start_time": "2025-08-11T04:46:01.859964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.718197,
   "end_time": "2025-08-11T04:46:02.291576",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-11T04:45:55.573379",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
